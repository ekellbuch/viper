# For example:
multiprocessing: False
path_pretrained_models: './pretrained_models'
dataset:
    data_path: 'data/ibl1_video' # Dataset path
    input_type: 'image'
    batch_size: 1
blip_v2_model_type: blip2-flan-t5-xl  # Change to blip2-flan-t5-xl for smaller GPUs
blip_half_precision: True
load_models:
    glip: True
    owlvit: False
    tcl: False
    gpt3_qa: True
    gpt3_general: False
    depth: False
    blip: True
    saliency: False
    xvlm: False
    codex: True

wandb: True
codex:
    prompt: ./prompts/chatapi.prompt                # Codex prompt file, which defines the API. (doesn't support video for now due to token limits)
    model: gpt-3.5-turbo                               #
#prompt: ./prompts/chatapi.prompt                # Codex prompt file, which defines the API. (doesn't support video for now due to token limits)

use_cached_codex: False
cached_codex_path: ''                               # Path to the csv results file from which to load Codex results
execute_code: True
log_every: 1

# Add more changes here, following the same format as base_config.yaml
